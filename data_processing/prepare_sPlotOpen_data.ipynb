{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d942f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import verde as vd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b5548",
   "metadata": {},
   "source": [
    "# Data file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6dbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The text files containing the sPlotOpen data is available at:\n",
    "# https://idata.idiv.de/ddm/Data/ShowData/3474?version=55\n",
    "sPlotOpen_occurrences_file = \"sPlotOpen_DT(1).txt\"\n",
    "sPlotOpen_metadata_file = \"sPlotOpen_header(2).txt\"\n",
    "worldclim_folder = \"worldclim\"\n",
    "soilgrids_folder = \"soilgrids250\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c975f7b",
   "metadata": {},
   "source": [
    "# Occurrence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23917835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(sPlotOpen_occurrences_file, delimiter=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = df[\"Species\"].unique()\n",
    "num_species = len(df[\"Species\"].unique())\n",
    "species_list\n",
    "\n",
    "for i, species in enumerate(species_list):\n",
    "    if type(species) != str:\n",
    "        nan_index = i\n",
    "\n",
    "species_list = np.delete(species_list, nan_index)\n",
    "species_list = np.sort(species_list)\n",
    "species2ind = {species: i for i, species in enumerate(species_list)}\n",
    "\n",
    "pd.DataFrame(list(species2ind.items()), columns=['Species Name', 'Index']).to_csv(\"species_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecd1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('PlotObservationID').aggregate({'Species': list})\n",
    "\n",
    "grouped['Species'] = grouped['Species'].apply(lambda x: [species2ind[species] for species in x if not pd.isna(species)])\n",
    "site2ind = {site: i for i, site in enumerate(grouped.index.values.tolist())}\n",
    "ind2site = {i: site for i, site in enumerate(grouped.index.values.tolist())}\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "species_encoded = mlb.fit_transform(grouped['Species'])\n",
    "print(species_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79208057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save species_occurrences file\n",
    "np.save(\"species_occurrences.npy\", species_encoded.astype(bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55930136",
   "metadata": {},
   "source": [
    "# Extract predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e454a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_metadata = pd.read_csv(sPlotOpen_metadata_file, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfce1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing data of WorldClim and SoilGrids with nearest non-missing value\n",
    "\n",
    "def find_nearest_non_missing(data, row, col, no_data_value, max_radius=100):\n",
    "    rows, cols = data.shape\n",
    "    for radius in range(1, max_radius + 1):\n",
    "        for dy in range(-radius, radius + 1):\n",
    "            for dx in range(-radius, radius + 1):\n",
    "                r, c = row + dy, col + dx\n",
    "                if 0 <= r < rows and 0 <= c < cols and not np.isclose(data[r, c], no_data_value, atol=0):\n",
    "                    return data[r, c].item()\n",
    "    return None  # Return None if no valid value is found within the max_radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e0d25",
   "metadata": {},
   "source": [
    "## Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_metadata[[\"PlotObservationID\",\"Longitude\", \"Latitude\"]].to_csv(\"location_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06972a31",
   "metadata": {},
   "source": [
    "## WorldClim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = plots_metadata[[\"Longitude\", \"Latitude\"]].values\n",
    "\n",
    "worldclim_variables = ['bio_' + str(i+1) for i in range(19)]\n",
    "worldclim_data = np.zeros((len(locations), 19), dtype=\"float32\")\n",
    "\n",
    "no_data_value = -3.4e+38\n",
    "\n",
    "for j, wv in enumerate(worldclim_variables):\n",
    "    print(f\"Processing {wv}\")\n",
    "    with rasterio.open(f\"{worldclim_folder}/wc2.1_30s_{wv}.tif\") as src:\n",
    "\n",
    "        data = src.read(1)\n",
    "        for i, val in enumerate(src.sample(locations)):\n",
    "            if np.isclose(val, no_data_value, atol=0):\n",
    "                x, y = locations[i]\n",
    "                row, col = src.index(x, y)\n",
    "                val = find_nearest_non_missing(data, row, col, no_data_value)\n",
    "            worldclim_data[i, j] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf41bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldclim_data = pd.DataFrame(worldclim_data, columns=worldclim_variables)\n",
    "worldclim_data[\"PlotObservationID\"] = plots_metadata[\"PlotObservationID\"]\n",
    "worldclim_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a45cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldclim_data.to_csv(\"worldclim_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a2334",
   "metadata": {},
   "source": [
    "## SoilGrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = plots_metadata[[\"Longitude\", \"Latitude\"]].values\n",
    "soilgrid_data = np.zeros((len(locations), 8))\n",
    "soil_variables = []\n",
    "\n",
    "for j, soil_file in enumerate(os.listdir(soilgrids_folder)):\n",
    "    soil_variable = soil_file[:6]\n",
    "    soil_variables.append(soil_variable)\n",
    "    print(f\"Processing {soil_variable}\")\n",
    "    with rasterio.open(f\"{soilgrids_folder}/{soil_file}\") as src:\n",
    "        if soil_variable in [\"ORCDRC\", \"CECSOL\", \"BDTICM\", \"BLDFIE\"]:\n",
    "            no_data_value = -32768.0\n",
    "        elif soil_variable in [\"PHIHOX\", \"CLYPPT\", \"SLTPPT\", \"SNDPPT\"]:\n",
    "            no_data_value = 255\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown missing value for {soil_variable}\")\n",
    "        data = src.read(1)\n",
    "        for i, val in enumerate(src.sample(locations)):\n",
    "            if val == no_data_value:\n",
    "                x, y = locations[i]\n",
    "                row, col = src.index(x, y)\n",
    "                val = find_nearest_non_missing(data, row, col, no_data_value)\n",
    "            soilgrid_data[i, j] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dcd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "soilgrid_data = pd.DataFrame(soilgrid_data, columns=soil_variables)\n",
    "soilgrid_data[\"PlotObservationID\"] = plots_metadata[\"PlotObservationID\"]\n",
    "soilgrid_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1af047",
   "metadata": {},
   "outputs": [],
   "source": [
    "soilgrid_data.to_csv(\"soilgrid_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf39b8",
   "metadata": {},
   "source": [
    "# Split the data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c291bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_csv(\"location_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seed = 42\n",
    "\n",
    "spacing = 1\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "\n",
    "locations = pd.read_csv(\"location_data.csv\")\n",
    "coordinates = np.array(locations[[\"Longitude\", \"Latitude\"]])\n",
    "\n",
    "data_indices = np.arange(len(coordinates))\n",
    "\n",
    "train_block, test_block = vd.train_test_split(\n",
    "    coordinates.transpose(),\n",
    "    data_indices,\n",
    "    spacing=spacing,\n",
    "    test_size=test_size,\n",
    "    random_state=split_seed,\n",
    ")\n",
    "train_indices, test_indices = train_block[1][0], test_block[1][0]\n",
    "\n",
    "train_block, val_block = vd.train_test_split(\n",
    "    coordinates[train_indices].transpose(),\n",
    "    train_indices,\n",
    "    spacing=spacing,\n",
    "    test_size=val_size/(1-test_size),\n",
    "    random_state=split_seed,\n",
    ")\n",
    "train_indices, val_indices = train_block[1][0], val_block[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "fig, ax = plt.subplots(figsize=(9, 8))\n",
    "\n",
    "palette = [\"#7a69e7\", \"#62ada8\", \"#eaa37f\"]\n",
    "\n",
    "world.plot(ax=ax, color='lightgray')\n",
    "\n",
    "markersize = 0.01\n",
    "\n",
    "gdf = gpd.GeoDataFrame(geometry=[Point(lon, lat) for lon, lat in coordinates[train_indices]])\n",
    "gdf.plot(ax=ax, color=palette[0], markersize=markersize, label=\"train\")\n",
    "\n",
    "gdf = gpd.GeoDataFrame(geometry=[Point(lon, lat) for lon, lat in coordinates[val_indices]])\n",
    "gdf.plot(ax=ax, color=palette[1], markersize=markersize, label=\"valid\")\n",
    "\n",
    "gdf = gpd.GeoDataFrame(geometry=[Point(lon, lat) for lon, lat in coordinates[test_indices]])\n",
    "gdf.plot(ax=ax, color=palette[2], markersize=markersize, label=\"test\")\n",
    "\n",
    "ax.grid(False)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "legend = ax.legend(loc='lower left')\n",
    "\n",
    "for handle in legend.legend_handles:\n",
    "    handle.set_sizes([20]) # increase the size of the markers in the legend\n",
    "\n",
    "ax.margins(0)\n",
    "\n",
    "ax.set_ylim((-63, 90))\n",
    "\n",
    "plt.savefig(\"splits_sPlotOpen.png\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b701c544",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepHSM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
