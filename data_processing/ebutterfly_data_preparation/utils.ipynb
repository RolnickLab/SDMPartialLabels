{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad81cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from pathlib import Path    \n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from geopy.distance import great_circle\n",
    "from shapely.geometry import MultiPoint\n",
    "from shapely.geometry import Polygon, Point\n",
    "from math import cos, radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b676c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/hagerradi/projects/Ecosystem_embeddings/ebutterfly/Darwin/0177350-230224095556074\"\n",
    "dataset_tag = \"ebutterfly_data_v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57c179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_data_path = os.path.join(root_dir, dataset_tag, \"environmental_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in glob.glob(env_data_path + '/*.npy'):\n",
    "    shutil.copy(file_name, env_data_path + '/B' + Path(file_name).name)\n",
    "\n",
    "for file_name in glob.glob(env_data_path + '/L*.npy'):\n",
    "    shutil.move(file_name, os.path.join(root_dir, dataset_tag, \"backup\", \"environmental_data\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_path = os.path.join(root_dir, dataset_tag, \"images\")\n",
    "for file_name in glob.glob(img_data_path + '/*.tif'):\n",
    "    shutil.copy(file_name, img_data_path + '/B' + Path(file_name).name)\n",
    "\n",
    "for file_name in glob.glob(img_data_path + '/L*.tif'):\n",
    "    shutil.move(file_name, os.path.join(root_dir, dataset_tag, \"backup\", \"images\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_path = os.path.join(root_dir, dataset_tag, \"butterfly_targets\")\n",
    "for file_name in glob.glob(targets_path + '/*.json'):\n",
    "    shutil.copy(file_name, targets_path + '/B' + Path(file_name).name)\n",
    "\n",
    "for file_name in glob.glob(targets_path + '/L*.json'):\n",
    "    shutil.move(file_name, os.path.join(root_dir, dataset_tag, \"backup\", \"butterfly_targets\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6193eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(root_dir, dataset_tag, \"images_visual\")\n",
    "for file_name in glob.glob(img_path + '/*.tif'):\n",
    "    shutil.copy(file_name, img_path + '/B' + Path(file_name).name)\n",
    "\n",
    "for file_name in glob.glob(img_path + '/L*.tif'):\n",
    "    shutil.move(file_name, os.path.join(root_dir, dataset_tag, \"backup\", \"images_visual\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be963a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_name in [\"train\", \"test\", \"valid\"]:\n",
    "    group_data = pd.read_csv(os.path.join(root_dir, dataset_tag, \"butterfly_hotspots_\" + str(group_name) + \".csv\"))\n",
    "    hotspots = group_data['hotspot_id'].values.tolist()\n",
    "    print(group_data)\n",
    "    new_hotspots = []\n",
    "    for hs in hotspots:\n",
    "        new_hotspots.append(\"B\"+hs)\n",
    "    \n",
    "    group_data['hotspot_id'] = new_hotspots\n",
    "    group_data.to_csv(os.path.join(root_dir, dataset_tag, \"butterfly_hotspots_\" + str(group_name) + \".csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d172ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_name in [\"train\", \"test\", \"valid\"]:\n",
    "    group_data = pd.read_csv(os.path.join(root_dir, dataset_tag, \"butterfly_hotspots_\" + str(group_name) + \".csv\"))\n",
    "    print(group_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947159ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from pathlib import Path    \n",
    "import shutil\n",
    "\n",
    "env_data_path = \"environmental_data\"\n",
    "for file_name in glob.glob(env_data_path + '/*.npy'):\n",
    "    shutil.move(file_name, env_data_path + '/B' + Path(file_name).name)\n",
    "    \n",
    "\n",
    "img_data_path = \"images\"\n",
    "for file_name in glob.glob(img_data_path + '/*.tif'):\n",
    "    shutil.move(file_name, img_data_path + '/B' + Path(file_name).name)\n",
    "\n",
    "targets_data_path = \"butterfly_targets\"\n",
    "for file_name in glob.glob(targets_data_path + '/*.json'):\n",
    "    shutil.move(file_name, targets_data_path + '/B' + Path(file_name).name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ba2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# targets_path = os.path.join(root_dir, dataset_tag, \"butterfly_targets\")\n",
    "targets_path = \"corrected_targets\"\n",
    "all_targets = []\n",
    "for file_name in tqdm(glob.glob(targets_path + '/*.json'):\n",
    "    targets = json.load(open(file_name))['probs']\n",
    "    targets = [i for i in targets if i != 0]\n",
    "    all_targets += targets\n",
    "\n",
    "print(len(all_targets))\n",
    "\n",
    "# all_targets = [i for i in all_targets if i != 0]\n",
    "# print(len([i for i in all_targets if i <= 1]))\n",
    "\n",
    "ret = plt.hist(all_targets, bins=5)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91220102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n",
      "Index(['C', 'Clements v2022 change', 'text for website v2022', 'category',\n",
      "       'English name', 'scientific name', 'authority', 'name and authority',\n",
      "       'range', 'order', 'family', 'extinct', 'extinct year', 'sort v2021',\n",
      "       'page 6.0'],\n",
      "      dtype='object')\n",
      "23\n",
      "23\n",
      "[2, 3, 4, 57, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 185, 239, 240, 282, 292, 314, 416, 417, 522]\n",
      "80\n",
      "80\n",
      "[2, 3, 4, 57, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 185, 239, 240, 282, 292, 314, 417, 522]\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/home/hagerradi/projects/Ecosystem_embeddings/ebutterfly/ebird_species\"\n",
    "species_df = pd.read_csv(os.path.join(root_dir, \"NEW_Clements-Checklist-v2022-October-2022.csv\"))\n",
    "\n",
    "species_list = open(os.path.join(root_dir, \"species_list_USA_birds.txt\")).read().split(\"\\n\")[0:-1]\n",
    "print(len(species_list))\n",
    "print(species_df.columns)\n",
    "\n",
    "species_family = []\n",
    "species_order = []\n",
    "\n",
    "for sp in species_list:\n",
    "    index_position = species_df[species_df['scientific name'] == sp].index[0]\n",
    "    species_family.append(species_df['family'][index_position])\n",
    "    species_order.append(species_df['order'][index_position])\n",
    "\n",
    "\n",
    "# f = open(os.path.join(root_dir, \"species_list_USA_birds_family.txt\"),'w')\n",
    "# f.write('\\n'.join(str(i) for i in species_family))\n",
    "# f.close()\n",
    "\n",
    "# f = open(os.path.join(root_dir, \"species_list_USA_birds_order.txt\"),'w')\n",
    "# f.write('\\n'.join(str(i) for i in species_order))\n",
    "# f.close()\n",
    "\n",
    "def save_mapping(species_l, file_name):\n",
    "    print(len(np.unique(species_l)))\n",
    "    unique_values , indices = np.unique(species_l, return_index=True)\n",
    "    species_l = np.array(species_l)\n",
    "    all_indices = {value: np.where(species_l == value)[0].tolist() for i, value in enumerate(unique_values)}\n",
    "    \n",
    "    all_v = []\n",
    "    for k, v in all_indices.items():\n",
    "        all_v += v\n",
    "\n",
    "    assert len(all_v) == len(species_list)\n",
    "\n",
    "    with open(os.path.join(root_dir, file_name), 'w') as f:\n",
    "        json.dump(all_indices, f)\n",
    "\n",
    "    \n",
    "    with open(os.path.join(root_dir, file_name), 'r') as f:\n",
    "        dict_loaded = json.load(f)\n",
    "    \n",
    "    print(len(dict_loaded.keys()))\n",
    "    print(list(dict_loaded.values())[0])\n",
    "\n",
    "save_mapping(species_l=species_order, file_name='bird_species_order_mapping.json')\n",
    "save_mapping(species_l=species_family, file_name='bird_species_family_mapping.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a434d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
