#where to save checkpoints
save_path: "/network/scratch/t/tengmeli/SDMPartialLabels/exps"
# load existing checkpoint for inference. If passing experiment folder instead (for multiple seeds), it will evaluate all of them.
load_ckpt_path: "/network/scratch/t/tengmeli/SDMPartialLabels/exps/1337/epoch=49-step=33449.ckpt"
save_preds_path: "" #"/network/scratch/h/hager.radi/ecosystem-embedding/baseline_resnet18_RGBNIR_ENV/preds_path"
log_comet: True

overfit_batches: 0.0
# maximum number of epochs to train for
max_epochs: 50
# base directory
base_dir: ""

dataloader_to_use: "SDMEnvDataset"

comet:
  project_name: "SDMPartialLabels"
  tags: ["MLP", "corrected_targets", "EnvNormalization", "satbird", "test"]
  experiment_name: "baseline_MLP_RTran" # specify for training, or use to report test results, TODO: also use to resume training
  experiment_key: "" # use to report test results,

experiment:
  #TASK and name should always be ebird_classifier --> maybe remove it 
  task: "ebird_classifier"
  name: "ebird_classifier"
  seed: 42
  module:
    #choose model : "resnet18" "resnet50" "inceptionv3" "linear" (just a linear model)
    model: "MlpEncoder"
    #"linear" or "linear_net" for a 2 layer MLP
    fc: "linear"
    #use pretrained weights ( torchvision )
    pretrained: False
    # resume training from another model (transfer learning), set empty if training from scratch
    resume: ""
    freeze: False
    #initializes biases of the output layer sothat sigmoid(bias) = mean over the training set for each species
    init_bias: ""
    means_path: ""
    lr: 0.0001



Rtran:
    use: true
    # Resnet18 or Resnet50
    backbone: "MlpEncoder"
    # use ImageNet pretrained weights
    pretrained_backbone: False
    # size of hidden feature vector: should match the backbone output feature size (512 for Resnet18, 2048 for Resnet50)
    features_size: 512
    # mask known labels out of the loss (true or false)
    masked_loss: False
    # quantized mask (1 if all positives to 1, > 1 to indicate bins)
    quantized_mask_bins: 4
    # use positional encoding
    use_positional_encoding: True
    # use the actual regression labels as input to the model and multiply with the embeddings (true or false)
    scale_embeddings_by_labels: False
    # max ratio of unknown labels during training
    train_known_ratio: 0.75
    # what known ratios do we consider when testing
    eval_known_ratio: 0.0 # [1.0, 0.9, 0.8, 0.5]
    # should the known values be masked out of the reported metrics or no
    mask_eval_metrics: True

# During testing, eval family of birds (0), or family of butterflies (1)
#or 0 for non songbirds and 1 for songbirds
predict_family_of_species: 0

optimizer: "AdamW"  #"Adam", "AdamW", "SGD"

losses:
#scale attribute is just for plotting if the values are very small
  criterion: "CE" #or MAE or MSE or Focal or RMSLE  (loss to choose for optim )

#auto lr will only work if there is only one optimizer
auto_lr_find: False
scheduler:
  name: "ReduceLROnPlateau" #"" for no schuler, "ReduceLROnPlateau" #"ReduceLROnPlateau" or "StepLR" "WarmUp"
  reduce_lr_plateau:
    factor: 0.5
    lr_schedule_patience: 20
  step_lr:
    step_size: 100
    gamma: 0.5
  warmup:
    warmup_epochs: 5
    max_epochs: 100

  cyclical:
    warmup_epochs: 10

variables: &default_vars
    ped_means: &ped_means []
    ped_std: &ped_std []
    bioclim_means: &bioclim_means []
    bioclim_std: &bioclim_std []

    sat_means: &sat_means []
    sat_stds: &sat_stds []



data:
  loaders:
    num_workers: 8
    batch_size: 128

  #o you want to use environmental data (pedological and bioclimatic (low res) data) #ped" or "bioclim" or both or empty list
  env: ['bio_1', 'bio_2',
       'bio_3', 'bio_4', 'bio_5', 'bio_6', 'bio_7', 'bio_8', 'bio_9', 'bio_10',
       'bio_11', 'bio_12', 'bio_13', 'bio_14', 'bio_15', 'bio_16', 'bio_17',
       'bio_18', 'bio_19', 'bdticm', 'bldfie', 'cecsol', 'clyppt', 'orcdrc',
       'phihox', 'sltppt', 'sndppt']

  #resolution of pedological and bioclimatic data in meters

  files:
    base: "/network/projects/ecosystem-embeddings/SatBird_data_v2/USA_summer"
    train: ["train_split.csv"]
    val: ["valid_split.csv"]
    test: ["test_split.csv"]

    targets_folder: ["targets"]
    env_data_folder: ["environmental"]
    images_folder: ["images"]
    correction_thresh: "range_maps.pkl" # range maps - threshold = False

    species_list: "/network/projects/ecosystem-embeddings/SatBird_data_v2/species_list_USA.txt"

  correction_factor:
     thresh:  # to train with RM

  target:
    type: "probs"  #binary for classification targets  or "probs" for regression (default should be "probs")

    # choose subset of birds : "ducks" for trying on species [37] or [2] for cooper's hawk (non passerine) "songbirds" (307 species) or None (full set 684 species) "not_songbirds"
    subset:  

  species: "all"
  species_eval:
  total_species: 670
trainer:
  auto_scale_batch_size: False
